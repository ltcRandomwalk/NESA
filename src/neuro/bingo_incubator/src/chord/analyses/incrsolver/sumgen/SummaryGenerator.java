package chord.analyses.incrsolver.sumgen;


import static com.google.common.base.Verify.verify;
import gnu.trove.iterator.TIntIntIterator;
import gnu.trove.iterator.TIntIterator;
import gnu.trove.map.hash.TIntIntHashMap;
import gnu.trove.set.hash.TIntHashSet;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeMap;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.google.common.collect.Sets;
import com.google.common.primitives.Ints;

import chord.project.Chord;
import chord.project.Config;
import chord.project.analyses.JavaAnalysis;
import chord.project.analyses.provenance.Tuple;
import chord.util.Timer;
import chord.util.tuple.object.Pair;

/**
 * -Dchord.incrsolver.summaryDir - Directory which contains input files and stores output files
 * -Dchord.incrsolver.numBench - [1]Number of benchmarks whose derivation trees will be combined for
 * 								 generating the summaries.
 * -Dchord.incrsolver.frontierW - [1000]Weight of the frontier nodes
 * -Dchord.incrsolver.summaryW -  [1]Comma-separated array of weights for the summary nodes, one value for
 * 								  each repetition count of the summary
 * -Dchord.incrsolver.numSummaries - [1]Number of summaries to generate
 * -Dchord.incrsolver.advMode - [false] False implies that multiple summaries are generated by calling the
 * 								maxsat solver in a loop, with one summary generated per loop iteration.
 * 								True implies that we make copies of the derivation graph and generate multiple
 * 								summaries in one call of the maxsat solver.
 * -Dchord.incrsolver.solver - [mcsls] Exact solver is mifumax. Approximate solver is mcsls
 * -Dchord.incrsolver.useOutset - [false] Use outsets or not.
 * -Dchord.incrsolver.numDisjuncts - [-1] Number of disjuncts to allow per derived tuple. Default of -1 means
 * 									 allow all disjuncts.
 * -Dchord.incrsolver.remUncond - [false] Compute and remove the unconditional summary first if set to true.
 * -Dchord.incrsolver.maxRepeat - [1] The maximum number of summaries a summary node should appear in.
 * -Dchord.incrsolver.maxOutsetSize - [100] Maximum size of the outset. Ranked by size of the provenance tree
 * 									  for a given out node.
 * -Dchord.incrsolver.exOutset - [false] Use extended outsets or not. Extended outset = outset + leaf nodes.
 * -Dchord.incrsolver.numMcslsSols - [10] number of solutions to be generated by the mcsls solver. Low value means
 * 									 more approximate solution.
 * -Dchord.incrsolver.perfect
 * -Dchord.incrsolver.useCoreRels [false] Add soft constraints only to boolean variables corresponding to tuples in core relations.
 * -Dchord.incrsolver.getParticipatingTuples [false] From the outset nodes, get the tuples which are involved in the derivation 
 *                                   of some app tuple. And, return after this task is done - don't proceed further.
 * 
 * @author Ravi
 *
 */
@Chord(name = "incr-summgenerator")
public class SummaryGenerator extends JavaAnalysis {
	private TupleIndex<Tuple> tupleIndex;
	private TupleIndex<TuplePlus> tuplePlusIndex;
	private HashSet<Clause> initClauses;
	private List<Clause> hardClauses;
	private TIntHashSet frontierTuples;
	private TIntIntHashMap outsetTupleCount;
	private TIntIntHashMap outsetTupleTreeCount;
	private List<Integer> sortedOutsetTupleTreeCount;
	private TIntIntHashMap summTupleCount;
	private Map<Integer, List<Integer>> frontierVarCopies;
	private Map<Integer, List<Integer>> summaryVarCopies;
	private List<Pair<Long, Clause>> softClauses;
	// Map from id of a frontier variable in tupleIndex to it corresponding
	// summary variable id in tupleIndex.
	private TIntIntHashMap frontierIdMap;
	private TIntHashSet uncondSolution;
	private TIntHashSet participatingTuples;
	
	private String summaryDir;
	private int numBench;
	private long frontierWeight;
	private String summaryWeightStr;
	private int[] summaryWeights;
	private int numSummaries;
	private boolean advancedMode;
	private String solver;
	private boolean useOutset;
	private boolean remUncond;
	private int numDisjuncts;
	private boolean isUncondMode; //current mode of operation. operates as a switch to toggle between the two modes.
	private int maxRepeat;
	private int maxOutsetSize;
	private boolean exOutset;
	private int numMcslsSols;
	private boolean perfectSumm;
	private boolean useCoreRels;
	private String coreRelList = "";
	private boolean getParticipatingTuples;

	@Override
	public void run() {
		summaryDir = System.getProperty("chord.incrsolver.summaryDir", "");
		numBench = Integer.getInteger("chord.incrsolver.numBench", 1);
		frontierWeight = Long.getLong("chord.incrsolver.frontierW", 1000);
		summaryWeightStr = System.getProperty("chord.incrsolver.summaryW", "1");
		numSummaries = Integer.getInteger("chord.incrsolver.numSummaries", 1);
		advancedMode = Boolean.getBoolean("chord.incrsolver.advMode");
		solver = System.getProperty("chord.incrsolver.solver", "mcsls");
		useOutset = Boolean.getBoolean("chord.incrsolver.useOutset");
		remUncond = Boolean.getBoolean("chord.incrsolver.remUncond");
		numDisjuncts = Integer.getInteger("chord.incrsolver.numDisjuncts", -1);
		maxRepeat = Integer.getInteger("chord.incrsolver.maxRepeat", numSummaries);
		maxOutsetSize = Integer.getInteger("chord.incrsolver.maxOutsetSize", 100);
		exOutset = Boolean.getBoolean("chord.incrsolver.exOutset");
		numMcslsSols = Integer.getInteger("chord.incrsolver.numMcslsSols", 10);
		perfectSumm = Boolean.getBoolean("chord.incrsolver.perfect");
		useCoreRels = Boolean.getBoolean("chord.incrsolver.useCoreRels");
		getParticipatingTuples = Boolean.getBoolean("chord.incrsolver.getParticipatingTuples");
		
		
		String[] summaryWeightArr = summaryWeightStr.split(",");
		if (this.advancedMode && summaryWeightArr.length != this.maxRepeat) {
			throw new RuntimeException("In advanced mode, a summary weight should be provided for each summary");
		}
		summaryWeights = new int[summaryWeightArr.length];
		for (int i = 0; i < summaryWeightArr.length; ++i) {
			summaryWeights[i] = Integer.parseInt(summaryWeightArr[i]);
		}

		this.tupleIndex = new TupleIndex<Tuple>();
		this.tuplePlusIndex = new TupleIndex<TuplePlus>();
		this.initClauses = new HashSet<Clause>();
		this.hardClauses = new ArrayList<Clause>();
		this.frontierTuples = new TIntHashSet();
		this.outsetTupleCount = new TIntIntHashMap();
		this.outsetTupleTreeCount = new TIntIntHashMap();
		this.sortedOutsetTupleTreeCount = new ArrayList<Integer>();
		this.summTupleCount = new TIntIntHashMap();
		this.frontierVarCopies = new HashMap<Integer, List<Integer>>();
		this.summaryVarCopies = new HashMap<Integer, List<Integer>>();
		this.frontierIdMap = new TIntIntHashMap();
		this.softClauses = new ArrayList<Pair<Long, Clause>>();
		this.isUncondMode = false;
		this.uncondSolution = new TIntHashSet();

		if (useCoreRels)
			setCoreRelList();
		
		for (int i = 0; i < numBench; ++i) {
			try {
				System.out.println("Loading constraints for benchmark " + i);
				FileInputStream in = new FileInputStream(summaryDir + File.separator + "summary_constraints_" + i);
				Set<Integer> seenLits = this.loadDTreeConstraints(in);
				in.close();
				for (Integer lit : seenLits) {
					int litCnt = summTupleCount.get(lit);
					if (litCnt == summTupleCount.getNoEntryValue()) {
						summTupleCount.put(lit, 1);
					} else {
						summTupleCount.put(lit, ++litCnt);
					}
				}
				System.out.println("Done loading constraints for benchmark " + i);
				System.out.println("Number of summary tuples: " + summTupleCount.size());

			} catch (IOException e) {
				throw new RuntimeException(e);
			}
			
			if (this.perfectSumm) {
				this.dumpPerfectSummary();
			}

			try {
				System.out.println("Loading frontier tuples for benchmark " + i);
				FileInputStream in = new FileInputStream(summaryDir + File.separator + "frontier_constraints_" + i);
				this.loadFrontierTuples(in);
				in.close();
				System.out.println("Done loading frontier tuples for benchmark " + i);
				System.out.println("Number of frontier tuples: " + frontierTuples.size());
			} catch (IOException e) {
				throw new RuntimeException(e);
			}
			
			if (useOutset) {
				try {
					System.out.println("Loading outset tuples for benchmark " + i);
					FileInputStream in = new FileInputStream(summaryDir + File.separator + "outset_constraints_" + i);
					this.loadOutsetTuples(in);
					in.close();
					System.out.println("Done loading outset tuples for benchmark " + i);
					System.out.println("Number of outset tuples: " + outsetTupleCount.size());
				/*	for (Map.Entry<Integer, Integer> entry : outsetTupleCount.entrySet()) {
						System.out.println(this.tupleIndex.getTuple(entry.getKey()) + ":" + entry.getValue());
					}
				*/	
				} catch (IOException e) {
					throw new RuntimeException(e);
				}
			}
		}
		
		if (this.perfectSumm) return;
		
		if (getParticipatingTuples) {
			participatingTuples = new TIntHashSet();
			this.getReversedCnf(new HashSet<Tuple>());
			dumpParticipatingTuples();
			return;
		}
		
		if (this.remUncond) this.isUncondMode = true;
		int prevUncondSize = 0;
		while (this.isUncondMode) {
			prevUncondSize = this.uncondSolution.size();
			this.numSummaries = 1;
			this.numDisjuncts = -1;
			this.frontierWeight = Long.MAX_VALUE;
			this.solver = "mcsls";
			this.maxOutsetSize = this.outsetTupleCount.size();
			
			this.generateConstraints(this.getReversedCnf(new HashSet<Tuple>()));
			System.out.println("Generated reverted constraints. Total constraints: " + hardClauses.size());
			this.groupTuples();
			System.out.println("Grouping of tuples done");
	//		this.generateSummaryCostConstraints();
			System.out.println("Generating cross-summary hard and soft constraints done. Total hard constraints: " + hardClauses.size());
			generateSoftConstraints();
			System.out.println("Generating soft constraints done. Total soft constraints: " + softClauses.size());
			generateSummaries();
			System.out.println("Unconditional solution size: " + this.uncondSolution.size());
			if (this.uncondSolution.size() == prevUncondSize) {
				this.isUncondMode = false;
				this.dumpUncondSummary();
				frontierWeight = Long.getLong("chord.incrsolver.frontierW", 10000);
				numSummaries = Integer.getInteger("chord.incrsolver.numSummaries", 1);
				numDisjuncts = Integer.getInteger("chord.incrsolver.numDisjuncts", -1);
				solver = System.getProperty("chord.incrsolver.solver", "mcsls");
				maxOutsetSize = Integer.getInteger("chord.incrsolver.maxOutsetSize", 100);
			}
		}
		
		this.generateConstraints(this.getReversedCnf(new HashSet<Tuple>()));
		System.out.println("Generated reverted constraints. Total constraints: " + hardClauses.size());
		this.groupTuples();
		System.out.println("Grouping of tuples done");
		this.generateSummaryCostConstraints();
		System.out.println("Generating cross-summary hard and soft constraints done. Total hard constraints: " + hardClauses.size());
		generateSoftConstraints();
		System.out.println("Generating soft constraints done. Total soft constraints: " + softClauses.size());
		generateSummaries();
	}

	
	private void setCoreRelList() {
		coreRelList = "CFC DI DVC FC reachableCM reachableT CICM";
	}
	
	
	private void filterUncondClauses(List<Clause> forwardClauses) {
		if (this.uncondSolution.size() == 0) return;
		tuplePlusIndex.clear();
		hardClauses.clear();
		softClauses.clear();
		frontierVarCopies.clear();
		summaryVarCopies.clear();
		frontierIdMap.clear();
		outsetTupleTreeCount.clear();
		sortedOutsetTupleTreeCount.clear();
		
		for (TIntIterator iter = this.uncondSolution.iterator(); iter.hasNext(); ) {
			int s = iter.next();
			frontierTuples.remove(s);
			outsetTupleCount.remove(s);
			summTupleCount.remove(s);
		}

		HashSet<Clause> filteredClauses = new HashSet<Clause>();
		for (Clause c : forwardClauses) {
			int y = c.ls[c.ls.length - 1]; //get head
			if (uncondSolution.contains(y)) {
				continue;
			} else {
				List<Integer> newLits = new ArrayList<Integer>();
				for (int lit : c.ls) {
					if (!uncondSolution.contains(Math.abs(lit))) {
						newLits.add(lit);
					}
				}
				filteredClauses.add(new Clause(Ints.toArray(newLits)));
			}
		}
		forwardClauses.clear();
		forwardClauses.addAll(filteredClauses);
	}
	
	private void generateConstraints(List<int[]> revConstraints) {
		int numCopies = 1;
		if (this.advancedMode) numCopies = this.numSummaries;
		for (int[] c : revConstraints) {
			for (int i = 0; i < numCopies; ++i) {
				int[] copyClause = new int[c.length];
				for (int k = 0; k < c.length; ++k) {
					if (Math.abs(c[k]) > tupleIndex.size()) {
						int varID = frontierIdMap.get(Math.abs(c[k]));
						if (varID != frontierIdMap.getNoEntryValue()) {
							// frontier variable
							if (tupleIndex.size() < Math.abs(varID)) throw new RuntimeException("Frontier variable should be mapped to a valid existing variable.");
							TuplePlus tPlus = new TuplePlus(Math.abs(varID), i, true, false);
							copyClause[k] = tuplePlusIndex.getIndex(tPlus) * Integer.signum(c[k]);
						} else {
							// auxillary variable
							TuplePlus tPlus = new TuplePlus(Math.abs(c[k]), i, false, true);
							copyClause[k] = tuplePlusIndex.getIndex(tPlus) * Integer.signum(c[k]);
						}
					} else {
						TuplePlus tPlus = new TuplePlus(Math.abs(c[k]), i, false, false);
						copyClause[k] = tuplePlusIndex.getIndex(tPlus) * Integer.signum(c[k]);
 					}
				}
				hardClauses.add(new Clause(copyClause));
			}
		}
	}
	
	private void groupTuples() {
		int frontierCopies = 0;
		int summaryCopies = 0;
		
		for (TuplePlus t: tuplePlusIndex) {
			if (!t.isAuxillary) {
				if (t.isFrontier) {
					++frontierCopies;
					List<Integer> frontierGrp = frontierVarCopies.get(t.id);
					if (frontierGrp == null) {
						frontierGrp = new ArrayList<Integer>();
						frontierVarCopies.put(t.id, frontierGrp);
					}
					frontierGrp.add(t.summId, tuplePlusIndex.getOldIndex(t));
				} else {
					++summaryCopies;
					List<Integer> summaryGrp = summaryVarCopies.get(t.id);
					if (summaryGrp == null) {
						summaryGrp = new ArrayList<Integer>();
						summaryVarCopies.put(t.id, summaryGrp);
					}
					summaryGrp.add(t.summId, tuplePlusIndex.getOldIndex(t));
				}
			}
		}
		System.out.println("Number of frontier groups: " + frontierVarCopies.size());
		System.out.println("Total number of frontier copies: " + frontierCopies);
		System.out.println("Number of summary groups: " + summaryVarCopies.size());
		System.out.println("Total number of summary copies: " + summaryCopies);
	}
	
	private void generateSummaryCostConstraints() {
		int auxVar = tuplePlusIndex.size() + 1;
		int numIter = 1;
		int maxRep = 1;
		if (this.advancedMode) { numIter = this.numSummaries; maxRep = this.maxRepeat; }
		
		for (Map.Entry<Integer, List<Integer>> summaryGrp : summaryVarCopies.entrySet()) {
	//		if (this.useOutset && !this.outsetTupleCount.containsKey(summaryGrp.getKey())) {
			if (this.useOutset && !this.sortedOutsetTupleTreeCount.contains(summaryGrp.getKey())) {
				continue;
			}
			
			int[][] costVars = new int[maxRep][numIter];
			for (int i = 0; i < maxRep; ++i) {
				for (int j = 0; j < numIter; ++j) {
					costVars[i][j] = 0;
				}
			}
			// The base case
			costVars[0][0] = auxVar++;
			hardClauses.add(new Clause(new int[] {-costVars[0][0], summaryGrp.getValue().get(0)}));

			for (int j = 1; j < numIter; ++j) {
				for (int i = 0; i <= j && i < maxRep; ++i) {
					costVars[i][j] = (costVars[i][j] == 0) ? auxVar++ : costVars[i][j];
					if (i < j) {
						costVars[i][j-1] = (costVars[i][j-1] == 0) ? auxVar++ : costVars[i][j-1];
						if (i == 0) {
							hardClauses.add(new Clause(new int[] {-costVars[i][j], costVars[i][j-1], summaryGrp.getValue().get(j)}));
						} else {
							int orId = auxVar++;
							hardClauses.add(new Clause(new int[] {-costVars[i][j], costVars[i][j-1], orId}));
							costVars[i-1][j-1] = (costVars[i-1][j-1] == 0) ? auxVar++ : costVars[i-1][j-1];
							hardClauses.add(new Clause(new int[] {-orId, costVars[i-1][j-1]}));
							hardClauses.add(new Clause(new int[] {-orId, summaryGrp.getValue().get(j)}));
						}
					} else {
						costVars[i-1][j-1] = (costVars[i-1][j-1] == 0) ? auxVar++ : costVars[i-1][j-1];
						hardClauses.add(new Clause(new int[] {-costVars[i][j], costVars[i-1][j-1]}));
						hardClauses.add(new Clause(new int[] {-costVars[i][j], summaryGrp.getValue().get(j)}));
					}
				}
			}
			if (isTupleOfCoreRel(summaryGrp.getKey())) {
				for (int i = 0; i < maxRep; ++i) {
					long cost = this.summaryWeights[i] * summTupleCount.get(summaryGrp.getKey());
					cost *= this.useOutset ? (outsetTupleCount.get(summaryGrp.getKey()) * outsetTupleTreeCount.get(summaryGrp.getKey())) : 1;
					softClauses.add(new Pair<Long,Clause>(cost, new Clause(new int[]{costVars[i][numIter - 1]})));
				}
			}
		}
	}
	
	
	private boolean isTupleOfCoreRel(int id) {
		if (useCoreRels) {
			Tuple t = tupleIndex.getTuple(id);
			if (coreRelList.indexOf(t.getRelName()) >= 0) 
				return true;
			else
				return false;
		} else {
			return true;
		}
	}
	
	
	private void generateSoftConstraints() {
		for (List<Integer> frontiers : frontierVarCopies.values()) {
			for (Integer f : frontiers) { 
				TuplePlus tPlus = tuplePlusIndex.getTuple(f);
				if (isTupleOfCoreRel(tPlus.id)) {
					softClauses.add(new Pair<Long, Clause>(this.frontierWeight, new Clause(new int[]{-f})));
				}
			}
		}
	}

	private void generateSummaries() {
		if (this.advancedMode) {
			MaxsatSolver maxSat = null;
			if (solver.equalsIgnoreCase("mifumax")) {
				maxSat = new Mifumax(hardClauses, softClauses);
			} else {
				maxSat = new Mcsls(hardClauses, softClauses, this.numMcslsSols);
			}
			Set<Integer> sol = maxSat.solveMaxSat();
			if (sol == null) {
				throw new RuntimeException("UNSAT!! In advanced mode, there should always be a SAT solution.");
			} else if (sol.size() == 0) {
				System.out.println("Empty summary !!");
			}
			Set<Integer> frontiers = new HashSet<Integer>();
			Map<Integer, Pair<Set<Tuple>, Set<Tuple>>> summaries = convertSolToSummaries(sol, frontiers);
			dumpSummary(summaries, 0); 
		} else {
			for (int i = 0; i < this.numSummaries; ++i) {
				MaxsatSolver maxSat = null;
				if (solver.equalsIgnoreCase("mifumax")) {
					maxSat = new Mifumax(hardClauses, softClauses);
				} else {
					maxSat = new Mcsls(hardClauses, softClauses, this.numMcslsSols);
				}
				Set<Integer> sol = maxSat.solveMaxSat();
				if (sol == null) {
					System.out.println("UNSAT while generating summary " + i);
					return;
				}
				Set<Integer> frontiers = new HashSet<Integer>();
				Map<Integer, Pair<Set<Tuple>, Set<Tuple>>> summaries = convertSolToSummaries(sol, frontiers);
				dumpSummary(summaries, i);
				int lits[] = new int[frontiers.size()];
				int k = 0;
				for (Integer f : frontiers) {
					lits[k++] = -f;
				}
				hardClauses.add(new Clause(lits));
			}
		}
	}
	
	private Map<Integer, Pair<Set<Tuple>, Set<Tuple>>> convertSolToSummaries(Set<Integer> sol, Set<Integer> frontiers) {
		Map<Integer, Pair<Set<Tuple>, Set<Tuple>>> summaries = new HashMap<Integer, Pair<Set<Tuple>, Set<Tuple>>>();
		for (Integer t : sol) {
			TuplePlus tplus = tuplePlusIndex.getTuple(t);
			if (tplus == null) continue;
			Pair<Set<Tuple>, Set<Tuple>> summary = summaries.get(tplus.summId);
			if (summary == null) {
				summary = new Pair<Set<Tuple>, Set<Tuple>>(new HashSet<Tuple>(), new HashSet<Tuple>());
				summaries.put(tplus.summId, summary);
			}
			Tuple tuple = tupleIndex.getTuple(tplus.id);
			if (tuple != null) {
				// not an auxillary variable
				if (tplus.isFrontier) {
					summary.val0.add(tuple);
					frontiers.add(t);
				// if (this.isUncondMode) uncondSolution.add(tplus.id);
				} else {
					// summary variable
					summary.val1.add(tuple);
					if (this.isUncondMode) uncondSolution.add(tplus.id);
				}
			}
		}
		System.out.println("Num summaries: " + summaries.size());
		if (!this.advancedMode && summaries.size() > 1) throw new RuntimeException("In simple mode, only one summary should be generated per iteration");
		if (this.isUncondMode && summaries.size() > 1) throw new RuntimeException("In unconditional mode, only one summary.");
		return summaries;
	}
	
	private void dumpParticipatingTuples() {
		try {
			System.out.println("Dumping participating tuples");
			
			PrintWriter tuplePW = new PrintWriter(new FileWriter(summaryDir + File.separator + "participating_tuples", true));
			for (TIntIterator iterator = participatingTuples.iterator(); iterator.hasNext(); ) {
				int t = iterator.next();
				Tuple tpl = tupleIndex.getTuple(t);
				tuplePW.println(tpl.toString());
			}
			tuplePW.flush();
			tuplePW.close();
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}
	
	private void dumpPerfectSummary() {
		try {
			System.out.println("Dumping unconditional summary");
			
			PrintWriter frntFileListPW = new PrintWriter(new FileWriter(summaryDir + File.separator + "union_condition_files", true));
			String frntFName = "union_frontier_perfect";
			String summaryFName = "union_summary_perfect";
			frntFileListPW.println(frntFName);

			PrintWriter frontierPW = new PrintWriter(new File(summaryDir + File.separator + frntFName));
			PrintWriter summaryPW = new PrintWriter(new File(summaryDir + File.separator + summaryFName));
			frontierPW.println(summaryFName);
			for (int summVar : this.summTupleCount.keys()){
				summaryPW.println(this.tupleIndex.getTuple(summVar));
			}
			frontierPW.flush();
			frontierPW.close();
			summaryPW.flush();
			summaryPW.close();
			frntFileListPW.flush();
			frntFileListPW.close();
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}
	
	private void dumpUncondSummary() {
		try {
			System.out.println("Dumping unconditional summary");
			
			PrintWriter frntFileListPW = new PrintWriter(new FileWriter(summaryDir + File.separator + "union_condition_files", true));
			String frntFName = "union_frontier_uncond";
			String summaryFName = "union_summary_uncond";
			frntFileListPW.println(frntFName);

			PrintWriter frontierPW = new PrintWriter(new File(summaryDir + File.separator + frntFName));
			PrintWriter summaryPW = new PrintWriter(new File(summaryDir + File.separator + summaryFName));
			frontierPW.println(summaryFName);
			for (TIntIterator iter = this.uncondSolution.iterator(); iter.hasNext(); ){
				summaryPW.println(this.tupleIndex.getTuple(iter.next()));
			}
			frontierPW.flush();
			frontierPW.close();
			summaryPW.flush();
			summaryPW.close();
			frntFileListPW.flush();
			frntFileListPW.close();
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}
 
	private void dumpSummary(Map<Integer, Pair<Set<Tuple>, Set<Tuple>>> summaries, int cnt) {
		if (this.isUncondMode) return;
		try {
			System.out.println("Dumping summaries");
			
			PrintWriter frntFileListPW = new PrintWriter(new FileWriter(summaryDir + File.separator + "union_condition_files", true));
			for (Pair<Set<Tuple>, Set<Tuple>> summary : summaries.values()){
				String frntFName = "union_frontier_" + String.valueOf(cnt);
				String summaryFName = "union_summary_" + String.valueOf(cnt);
				frntFileListPW.println(frntFName);

				PrintWriter frontierPW = new PrintWriter(new File(summaryDir + File.separator + frntFName));
				PrintWriter summaryPW = new PrintWriter(new File(summaryDir + File.separator + summaryFName));
				frontierPW.println(summaryFName);
				
				for (Tuple t : summary.val0) {
					frontierPW.println(t);
				}
				
				for (Tuple t : summary.val1) {
					summaryPW.println(t);
				}
				
				frontierPW.flush();
				frontierPW.close();
				summaryPW.flush();
				summaryPW.close();
				
				cnt++;
			}
			frntFileListPW.flush();
			frntFileListPW.close();
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}

	public void loadFrontierTuples(InputStream in) {
		if (summTupleCount.isEmpty()) throw new RuntimeException("LoadDTreeConstraints first");
		try {
			BufferedReader reader =
				new BufferedReader(new InputStreamReader(in));
			String line = null;
			while ((line = reader.readLine()) != null) {
				Tuple t = new Tuple(line);
				int atId = this.tupleIndex.getIndex(t);
				if (!summTupleCount.containsKey(atId)) throw new RuntimeException("Frontier tuples should have been seen in dtree constraints");
				frontierTuples.add(atId);
			}
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}
	
	public void loadOutsetTuples(InputStream in) {
		if (summTupleCount.isEmpty()) throw new RuntimeException("LoadDTreeConstraints first");
		try {
			int summCnt = 0;
			int fCnt = 0;
			BufferedReader reader =
				new BufferedReader(new InputStreamReader(in));
			String line = null;
			while ((line = reader.readLine()) != null) {
				Tuple t = new Tuple(line);
				int atId = this.tupleIndex.getIndex(t);
				if (!summTupleCount.containsKey(atId)) continue;
				summCnt++;
				if (frontierTuples.contains(atId)) fCnt++;
				int outCount = outsetTupleCount.get(atId);
				if (outCount == outsetTupleCount.getNoEntryValue()) {
					outsetTupleCount.put(atId, 1);
				} else {
					outsetTupleCount.put(atId, ++outCount);
				}
			}
			System.out.println("Number of outset tuples in summaries: " + summCnt);
			System.out.println("Number of outset tuples in frontiers: " + fCnt);
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
	}

	public Set<Integer> loadDTreeConstraints(InputStream in) {
		Set<Integer> seenLits = new HashSet<Integer>();
		try {
			BufferedReader reader =
				new BufferedReader(new InputStreamReader(in));
			String line = null;
			SortedSet<Integer> literals = Sets.newTreeSet();
			while ((line = reader.readLine()) != null) {
				literals.clear();
				String litStrs[] = line.split(", ");
				for (int i = 0; i < litStrs.length; i++) {
					String litSegs[] = litStrs[i].split(" ");
					boolean isNeg = (litSegs.length > 1);
					String atomStr = litSegs[litSegs.length - 1];
					int atId;
					Tuple t = new Tuple(atomStr);
					atId = this.tupleIndex.getIndex(t);
					seenLits.add(atId);
					if (isNeg) {
						atId = 0 - atId;
					}
					literals.add(atId);
				}
				initClauses.add(new Clause(Ints.toArray(literals)));
			}
		} catch (IOException e) {
			throw new RuntimeException(e);
		}
		return seenLits;
	}

	public List<int[]> getReversedCnf(
		Iterable<Tuple> parameters
		) {
		// Phase 0: Assert formulas are of the right shape.
		{
			long start = System.nanoTime();
			for (Clause c : initClauses) {
				int posCount = 0;
				for (int l : c.ls) if (l > 0) ++posCount;
				verify(posCount == 1, "I can only deal with definite Horn formulas. (8fdwad)");
				for (int i = 1; i < c.ls.length; ++i)
					verify(c.ls[i-1] < c.ls[i], "Clauses should be sorted. (d98wqhed)");
				for (int l : c.ls)
					verify(tupleIndex.getTuple(Math.abs(l)) != null, "That's surprising! (8sdb8ad)");
			}
			System.out.printf("XXX PROF phase 0 %.02f%n", (1e-9)*(System.nanoTime()-start));
		    System.out.println("XXX PROF phase 0. Num clauses: " + initClauses.size());
		}

		// Phase 1: Simulate a Datalog run, and keep only forward-going clauses.
		List<Clause> forwardClauses = Lists.newArrayList();
		{
			long start = System.nanoTime();
			Map<Integer, List<Clause>> watch = Maps.newHashMap();
			Set<Integer> justified = Sets.newHashSet();
			Set<Integer> now = Sets.newHashSet();
			Set<Integer> nxt = Sets.newHashSet();

			for (Tuple p : parameters) nxt.add(tupleIndex.getIndex(p));
			for (Clause c : initClauses) {
				if (c.ls.length == 1) {
					nxt.add(c.ls[0]);
					forwardClauses.add(c);
				} else {
					List<Clause> cs = watch.get(-c.ls[0]);
					if (cs == null) {
						cs = Lists.newArrayList();
						watch.put(-c.ls[0], cs);
					}
					cs.add(c);
				}
			}

			while (!nxt.isEmpty()) {
				{ Set<Integer> tmpSI = now; now = nxt; nxt = tmpSI; nxt.clear(); }
				justified.addAll(now);
				for (Integer x : now) {
					List<Clause> ws = watch.get(x);
					if (ws == null) continue;
					for (Clause w : ws) {
						int y = w.ls[w.ls.length - 1];
						if (justified.contains(y)) continue; // w isn't a forward clause
						int i = w.ls.length - 2;
						while (i >= 0 && justified.contains(-w.ls[i])) --i;
						if (i >= 0) {
							List<Clause> zs = watch.get(-w.ls[i]);
							if (zs == null) {
								zs = Lists.newArrayList();
								watch.put(-w.ls[i], zs);
							}
							zs.add(w);
						} else {
							nxt.add(y);
							forwardClauses.add(w);
							if (false) {
								System.out.printf("DBG use %s <-", tupleIndex.getTuple(y));
								for (int l : w.ls) if (l < 0)
									System.out.printf(" %s", tupleIndex.getTuple(-l));
								System.out.printf("\n");
							}
						}
					}
				}
			}
			
			System.out.printf("XXX PROF phase 1 %.02f%n", (1e-9)*(System.nanoTime()-start));
		    System.out.println("XXX PROF phase 1. Num forward clauses: " + forwardClauses.size());
		    
		    this.filterUncondClauses(forwardClauses);
		    
		    System.out.printf("XXX PROF phase 1a %.02f%n", (1e-9)*(System.nanoTime()-start));
		    System.out.println("XXX PROF phase 1a. Num filtered forward clauses: " + forwardClauses.size());
		}

		// Phase 2: Reverse implications.
		TIntHashSet headSet = new TIntHashSet();
		TIntHashSet bodySet = new TIntHashSet();
		List<int[]> revCnf = Lists.newArrayList();
		{
			long start = System.nanoTime();

			// Phase 2.1. Build Graph.
			Map<Integer, List<Clause>> withHead = Maps.newHashMap();
			for (Clause c : forwardClauses) {
				int y = c.ls[c.ls.length - 1];
				headSet.add(y);
				List<Clause> cs = withHead.get(y);
				if (cs == null) {
					cs = Lists.newArrayList();
					withHead.put(y, cs);
				}
				cs.add(c);
			}

			// Phase 2.2. Backward reachability from queries.
			{
				TIntHashSet done = new TIntHashSet();
				TIntHashSet todo = new TIntHashSet();

				// for (Tuple q : queries) todo.add(tupleIndex.getOldIndex(q));
				for (TIntIterator iterator = headSet.iterator(); iterator.hasNext(); ) todo.add(iterator.next());

				int auxVar = tupleIndex.size();  // last used index
				
				System.out.println("Init number of leaf nodes for reversal: " + todo.size());
				// handle common case with single derivation for a head tuple
				for (Map.Entry<Integer, List<Clause>> entry : withHead.entrySet()) {
					int y = entry.getKey();
					// A frontier tuple may be the head of a clause in which all its body tuples are in the library. This can
					// happen because of disjunction. i.e. By one disjunct, a head tuple of a constraint may get defined as a 
					// frontier tuple and by another disjunct, it may not be a frontier tuple (i.e it may be derived by purely 
					// library tuples). In the second case, this constraint will occur as a clause.
					if (entry.getValue().size() == 1 && !frontierTuples.contains(Math.abs(y)) ) {
						todo.remove(y);
						done.add(y);
						int ny = -y;
						Clause c = entry.getValue().get(0);
						if (c.ls.length == 1) {
							revCnf.add(new int[] {y});
						} else {
							for (int i = c.ls.length - 2; i >= 0; --i) {
								int x = -c.ls[i];
								bodySet.add(x);
								revCnf.add(new int[] {ny, x});
							}
						}
					}
				}
				System.out.println("Number of leaf nodes for reversal after handling common case: " + todo.size());
				System.out.println("Number of leaf nodes handled after common case: " + done.size());
				int origBranchingSize = 0;
				int curtailedBranchingSize = 0;
				while (!todo.isEmpty()) {
					int y = todo.iterator().next(); todo.remove(y);
					done.add(y);
					List<Clause> cs = withHead.get(y);
					if (cs == null) {
						// verify(parameterHandler.isParam(tupleIndex.getTuple(y)));
						continue;
					}
					boolean isCurrFrontierTuple = frontierTuples.contains(Math.abs(y));
					if (cs.size() > 1 || isCurrFrontierTuple) {
						// In DTreeDumper, the EDB tuples in the body of a constraint are dropped. That is why, there will be
						// cases when the below "if" condition will be satisfied. The conditions are : the head tuple is a frontier tuple,
						// there is only one disjunct and the number of literals in the clause is 1 which means just the head tuple itself.
						if (isCurrFrontierTuple && cs.size() == 1 && cs.get(0).ls.length == 1) {
							revCnf.add(new int[] {-y, ++auxVar});
							frontierIdMap.put(auxVar, y);
						} else {
			/*				int[] orClause = null;
							int csSize = (this.numDisjuncts == -1) ? cs.size() : ((this.numDisjuncts < cs.size()) ? this.numDisjuncts : cs.size());
							if (isCurrFrontierTuple) {
								orClause = new int[cs.size() + 2];
							} else {
								orClause = new int[cs.size() + 1];
							}

							int i = 1;
							for (Clause c : cs) {
								orClause[i] = auxVar + i; ++i;
							}
							if (isCurrFrontierTuple) {
								orClause[i] = auxVar + i;
								frontierIdMap.put(auxVar + i, y);
							}

							orClause[0] = -y;
							revCnf.add(orClause);
							for (Clause c : cs) {
								int ny = -(++auxVar);
								for (int j = c.ls.length - 2; j >= 0; --j) {
									int x = -c.ls[j];
									if (!done.contains(x)) todo.add(x);
									revCnf.add(new int[] {ny, x});
								}
							}
							if (isCurrFrontierTuple) ++auxVar;
			*/				
							int[] orClause = null;
							int csSize = (this.numDisjuncts == -1) ? cs.size() : ((this.numDisjuncts < cs.size()) ? this.numDisjuncts : cs.size());
							origBranchingSize += cs.size();
							curtailedBranchingSize += csSize;
							if (isCurrFrontierTuple) {
								orClause = new int[csSize + 2];
							} else {
								orClause = new int[csSize + 1];
							}

							int i = 1, cutOff = 0;
							for (Clause c : cs) {
								if (cutOff >= csSize) {
									break;
								} else {
									orClause[i] = auxVar + i; ++i;
									cutOff++;
								}
							}
							if (isCurrFrontierTuple) {
								orClause[i] = auxVar + i;
								frontierIdMap.put(auxVar + i, y);
							}

							orClause[0] = -y;
							revCnf.add(orClause);
							
							cutOff = 0;
							for (Clause c : cs) {
								if (cutOff >= csSize) {
									break;
								} else {
									cutOff++;
									int ny = -(++auxVar);
									for (int j = c.ls.length - 2; j >= 0; --j) {
										int x = -c.ls[j];
										bodySet.add(x);
										if (!done.contains(x)) todo.add(x);
										revCnf.add(new int[] {ny, x});
									}
								}
							}
							if (isCurrFrontierTuple) ++auxVar;
						}
					} else {
						throw new RuntimeException("Should have been handled by the common case pass!!");
					}
					
				}
				System.out.println("Original branching size: " + origBranchingSize);
				System.out.println("Curtailed branching size: " + curtailedBranchingSize);
				
				System.out.println("Total head elements: " + headSet.size());
				headSet.removeAll(bodySet);
				System.out.println("Total terminal elements: " + headSet.size());
				if (this.exOutset) {
					for (TIntIterator iterator = headSet.iterator(); iterator.hasNext(); ) {
						outsetTupleCount.put(iterator.next(), 1);
					}
					System.out.println("Total outset elements: " + outsetTupleCount.size());
				}
				
				// Cnt number of nodes backward reachable from a given out node
				int largestTree = 0;
				for (int outVar : outsetTupleCount.keys()) {
					int cnt = 1;
					todo.clear();
					done.clear();
					todo.add(outVar);
					if (getParticipatingTuples) participatingTuples.add(outVar);
					while (!todo.isEmpty()) {
						int y = todo.iterator().next(); todo.remove(y);
						done.add(y);
						List<Clause> cs = withHead.get(y);
						if (cs == null) {
							// verify(parameterHandler.isParam(tupleIndex.getTuple(y)));
							continue;
						}
						for (Clause c : cs) {
							for (int j = c.ls.length - 2; j >= 0; --j) {
								int x = -c.ls[j];
								if (!done.contains(x)) {
									todo.add(x);
									if (getParticipatingTuples) participatingTuples.add(x);
								}
								cnt++;
							}
						}
					}
					outsetTupleTreeCount.put(outVar, cnt);
					if (cnt > largestTree) largestTree = cnt;
				//	System.out.println("Out id: " + outVar + ", Tree size: " + cnt);
				}
				TreeMap<Integer, Set<Integer>> sortedCount = new TreeMap<Integer, Set<Integer>>();
				for (int e : outsetTupleTreeCount.keys()) {
			//	for (Map.Entry<Integer, Integer> e : outsetTupleCount.entrySet()) {
					int val = outsetTupleTreeCount.get(e);
					Set<Integer> outT = sortedCount.get(val);
					if (outT == null) {
						outT = new HashSet<Integer>();
						sortedCount.put(val, outT);
					}
					outT.add(e);
				}
				for (Map.Entry<Integer, Set<Integer>> e : sortedCount.descendingMap().entrySet()) {
				//	System.out.println("Count: " + e.getKey() + ", num elems: " + e.getValue().size());
					this.sortedOutsetTupleTreeCount.addAll(e.getValue());
					if (this.sortedOutsetTupleTreeCount.size() > this.maxOutsetSize) {
						break;
					}
				}
				
				System.out.println("Largest outset provenance size: " + largestTree);
				System.out.println("XXX PROF phase 2a. Generated provenance tree size for outset tuples.");
				System.out.printf("XXX PROF phase 2a %.02f%n", (1e-9)*(System.nanoTime()-start));
			}
			System.out.printf("XXX PROF phase 2 %.02f%n", (1e-9)*(System.nanoTime()-start));
			System.out.println("XXX PROF phase 2. Num rev clauses: " + revCnf.size());
		}
		
		System.out.println("Reverse constraint generation done");

		return revCnf;
	}
	
	private static final class TuplePlus {
//		static TupleIndex<Tuple> tIndex = tupleIndex;
		public int id;
		public int summId;
		public boolean isFrontier;
		public boolean isAuxillary;
		private int hash;
		TuplePlus(int id, int summId, boolean isFrontier, boolean isAuxillary) {
			this.id = id;
			this.summId = summId;
			this.isFrontier = isFrontier;
			this.isAuxillary = isAuxillary;
			hash ^= id;
			hash ^= summId;
			hash += isFrontier ? 3 : 1;
			hash += isFrontier ? 4 : 1;
		}
		@Override public boolean equals(Object other) {
			if (!(other instanceof TuplePlus)) return false;
			TuplePlus c = (TuplePlus) other;
			return
				hash == c.hash && id == c.id && summId == c.summId && 
				isFrontier == c.isFrontier && isAuxillary == c.isAuxillary;
		}
		@Override public int hashCode() { return hash; }
		
		@Override
		public String toString() {
//			return ("S: " + summId + ", T: " + tIndex.getTuple(id) + ", F: " + isFrontier + ", A: " + isAuxillary);
			return ("S: " + summId + ", T: " + id + ", F: " + isFrontier + ", A: " + isAuxillary);
		}
	}
}
